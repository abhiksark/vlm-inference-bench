# docker/vllm-awq/docker-compose.yaml
version: '3.8'

services:
  vllm-awq:
    build: .
    ports:
      - "${PORT:-8001}:8001"
    environment:
      - CUDA_VISIBLE_DEVICES=${CUDA_DEVICE:-0}
      - MODEL_NAME=${MODEL_NAME:-Qwen/Qwen3-VL-4B-Instruct-AWQ}
      - QUANTIZATION=awq
      - DTYPE=float16
      - GPU_MEM_UTIL=${GPU_MEM_UTIL:-0.85}
    volumes:
      - ~/.cache/huggingface:/root/.cache/huggingface
    shm_size: '16gb'
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['${CUDA_DEVICE:-0}']
              capabilities: [gpu]
