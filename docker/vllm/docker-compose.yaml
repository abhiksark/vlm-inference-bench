# docker/vllm/docker-compose.yaml
version: '3.8'

services:
  vllm:
    build: .
    ports:
      - "${PORT:-8000}:8000"
    environment:
      - CUDA_VISIBLE_DEVICES=${CUDA_DEVICE:-0}
      - MODEL_NAME=${MODEL_NAME:-Qwen/Qwen3-VL-4B-Instruct}
      - DTYPE=${DTYPE:-bfloat16}
      - GPU_MEM_UTIL=${GPU_MEM_UTIL:-0.85}
    volumes:
      - ~/.cache/huggingface:/root/.cache/huggingface
    shm_size: '16gb'
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['${CUDA_DEVICE:-0}']
              capabilities: [gpu]
