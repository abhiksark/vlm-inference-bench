# configs/benchmark_ollama_thinking.yaml
# Benchmark configuration for Ollama backend (thinking model)

backend:
  type: "ollama"
  base_url: "http://localhost:28434"
  model: "qwen3-vl:4b-thinking"
  max_new_tokens: 256
  timeout: 120

data:
  video_dir: "video"
  sample_size: 5
  frame_sampling: "uniform"
  frames_per_video: 4
  target_fps: 1

benchmark:
  warmup_runs: 1
  num_runs: 5
  batch_sizes: [1]
  measure_memory: true
  measure_gpu_util: true
  save_individual_results: true

output:
  results_dir: "results"
  save_format: ["json", "csv"]
