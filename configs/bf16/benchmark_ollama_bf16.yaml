# configs/bf16/benchmark_ollama_bf16.yaml
# Ollama with F16 GGUF (closest to bfloat16)

backend:
  type: "ollama"
  base_url: "http://localhost:28434"
  model: "qwen3-vl:4b-instruct-bf16"
  max_new_tokens: 256
  timeout: 600

data:
  video_dir: "video"
  sample_size: 5
  frame_sampling: "uniform"
  frames_per_video: 4
  target_fps: 1

benchmark:
  warmup_runs: 1
  num_runs: 5
  batch_sizes: [1]
  measure_memory: true
  measure_gpu_util: true
  save_individual_results: true

output:
  results_dir: "results/bf16"
  save_format: ["json", "csv"]
